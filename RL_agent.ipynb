{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e460eb",
   "metadata": {},
   "source": [
    "## 1. A gentle example of using ReinforcementLearning.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec02870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg;\n",
    "Pkg.add(\"ReinforcementLearning\");\n",
    "using ReinforcementLearning;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb0dd9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# RandomWalk1D\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                Value |\n",
       "|:----------------- | --------------------:|\n",
       "| NumAgentStyle     |        SingleAgent() |\n",
       "| DynamicStyle      |         Sequential() |\n",
       "| InformationStyle  | PerfectInformation() |\n",
       "| ChanceStyle       |      Deterministic() |\n",
       "| RewardStyle       |     TerminalReward() |\n",
       "| UtilityStyle      |         GeneralSum() |\n",
       "| ActionStyle       |   MinimalActionSet() |\n",
       "| StateStyle        | Observation{Int64}() |\n",
       "| DefaultStateStyle | Observation{Int64}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Base.OneTo(7)`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(2)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "4\n",
       "```\n"
      ],
      "text/plain": [
       "# RandomWalk1D\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                Value |\n",
       "|:----------------- | --------------------:|\n",
       "| NumAgentStyle     |        SingleAgent() |\n",
       "| DynamicStyle      |         Sequential() |\n",
       "| InformationStyle  | PerfectInformation() |\n",
       "| ChanceStyle       |      Deterministic() |\n",
       "| RewardStyle       |     TerminalReward() |\n",
       "| UtilityStyle      |         GeneralSum() |\n",
       "| ActionStyle       |   MinimalActionSet() |\n",
       "| StateStyle        | Observation{Int64}() |\n",
       "| DefaultStateStyle | Observation{Int64}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Base.OneTo(7)`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(2)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "4\n",
       "```\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = RandomWalk1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16882073",
   "metadata": {},
   "source": [
    "### random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87c63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = action_space(env)\n",
    "while true\n",
    "    env(rand(A))\n",
    "    is_terminated(env) && break\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61151f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "            \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "          \u001b[38;5;8m1\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⢱\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡏\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢰\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢰\u001b[0m\u001b[38;5;2m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢣\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡸\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⡆\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢇\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⡆\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⡎\u001b[0m⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⡎\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⠘\u001b[0m\u001b[38;5;2m⡄\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score   \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠤⠤⠤⠤⠤⠤\u001b[38;5;2m⢼\u001b[0m⠤⠤⠤⠤\u001b[38;5;2m⡧\u001b[0m⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤\u001b[38;5;2m⡧\u001b[0m⠤⠤⠤\u001b[38;5;2m⢼\u001b[0m⠤⠤\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⠸\u001b[0m\u001b[38;5;2m⡀\u001b[0m⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢱\u001b[0m⠀⠀⠀\u001b[38;5;2m⡜\u001b[0m⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀\u001b[38;5;2m⡸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⠸\u001b[0m\u001b[38;5;2m⡀\u001b[0m⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢣\u001b[0m⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀\u001b[38;5;2m⢰\u001b[0m\u001b[38;5;2m⠁\u001b[0m⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢣\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢇\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⣆\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-1\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⣿\u001b[0m⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "            ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0], 0.0, true)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\n",
    "    RandomPolicy(),\n",
    "    RandomWalk1D(),\n",
    "    StopAfterEpisode(10),\n",
    "    TotalRewardPerEpisode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08a1eb",
   "metadata": {},
   "source": [
    "### tabular policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92206641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tabular policy\n",
    "S = state_space(env);\n",
    "A = action_space(env);\n",
    "NS, NA = length(S),A;\n",
    "tabular_policy = TabularPolicy(;table=Dict(zip(1:NS, fill(2,NS))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d7553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "           \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "         \u001b[38;5;8m2\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score  \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "           ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "           ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.0, true)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\n",
    "   tabular_policy,\n",
    "   RandomWalk1D(),\n",
    "   StopAfterEpisode(10),\n",
    "   TotalRewardPerEpisode()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d4fc1",
   "metadata": {},
   "source": [
    "### `QBasedPolicy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0444114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Flux\")\n",
    "using Flux: InvDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1b99d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(QBasedPolicy)\n",
       "├─ learner => typename(MonteCarloLearner)\n",
       "│  ├─ approximator => typename(TabularApproximator)\n",
       "│  │  ├─ table => 2×7 Matrix{Float64}\n",
       "│  │  └─ optimizer => typename(InvDecay)\n",
       "│  │     ├─ gamma => 1.0\n",
       "│  │     └─ state => typename(IdDict)\n",
       "│  ├─ γ => 1.0\n",
       "│  ├─ kind => typename(ReinforcementLearningZoo.FirstVisit)\n",
       "│  └─ sampling => typename(ReinforcementLearningZoo.NoSampling)\n",
       "└─ explorer => typename(EpsilonGreedyExplorer)\n",
       "   ├─ ϵ_stable => 0.1\n",
       "   ├─ ϵ_init => 1.0\n",
       "   ├─ warmup_steps => 0\n",
       "   ├─ decay_steps => 0\n",
       "   ├─ step => 1\n",
       "   ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "   └─ is_training => true\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `MonteCarloLearner + EpsilonGreedyExplorer`\n",
    "policy = QBasedPolicy(\n",
    "   learner = MonteCarloLearner(;\n",
    "           approximator=TabularQApproximator(\n",
    "               ;n_state = NS,\n",
    "               n_action = NA,\n",
    "               opt = InvDecay(1.0)\n",
    "           )\n",
    "       ),\n",
    "   explorer = EpsilonGreedyExplorer(0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc3eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "            \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "          \u001b[38;5;8m0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score   \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-2\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "            ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], 0.0, true)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\n",
    "   policy,\n",
    "   RandomWalk1D(),\n",
    "   StopAfterEpisode(10),\n",
    "   TotalRewardPerEpisode()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94580694",
   "metadata": {},
   "source": [
    "### wrap the policy + trajectory into the 'agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d03fb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(Agent)\n",
       "├─ policy => typename(QBasedPolicy)\n",
       "│  ├─ learner => typename(MonteCarloLearner)\n",
       "│  │  ├─ approximator => typename(TabularApproximator)\n",
       "│  │  │  ├─ table => 2×7 Matrix{Float64}\n",
       "│  │  │  └─ optimizer => typename(InvDecay)\n",
       "│  │  │     ├─ gamma => 1.0\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ γ => 1.0\n",
       "│  │  ├─ kind => typename(ReinforcementLearningZoo.FirstVisit)\n",
       "│  │  └─ sampling => typename(ReinforcementLearningZoo.NoSampling)\n",
       "│  └─ explorer => typename(EpsilonGreedyExplorer)\n",
       "│     ├─ ϵ_stable => 0.1\n",
       "│     ├─ ϵ_init => 1.0\n",
       "│     ├─ warmup_steps => 0\n",
       "│     ├─ decay_steps => 0\n",
       "│     ├─ step => 33\n",
       "│     ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "│     └─ is_training => true\n",
       "└─ trajectory => typename(Trajectory)\n",
       "   └─ traces => typename(NamedTuple)\n",
       "      ├─ state => 0-element Vector{Int64}\n",
       "      ├─ action => 0-element Vector{Int64}\n",
       "      ├─ reward => 0-element Vector{Float32}\n",
       "      └─ terminal => 0-element Vector{Bool}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Agent(policy=policy, trajectory=VectorSARTTrajectory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459523fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "            \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "          \u001b[38;5;8m1\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⡏\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⡎\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;2m⡸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score   \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠤⠤\u001b[38;5;2m⡧\u001b[0m⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⡜\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-1\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "            ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([-1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.0, true)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(agent, env, StopAfterEpisode(10), TotalRewardPerEpisode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f480c26",
   "metadata": {},
   "source": [
    "## 2. PPO algorithm for pendulum problem (built-in experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f9cc1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"StableRNGs\")\n",
    "Pkg.add(\"Distributions\")\n",
    "using ReinforcementLearning\n",
    "using StableRNGs\n",
    "using Flux\n",
    "using Flux.Losses\n",
    "using Distributions\n",
    "\n",
    "function RL.Experiment(\n",
    "    ::Val{:JuliaRL},\n",
    "    ::Val{:PPO},\n",
    "    ::Val{:Pendulum},\n",
    "    ::Nothing;\n",
    "    save_dir = nothing,\n",
    "    seed = 123,\n",
    ")\n",
    "    rng = StableRNG(seed)\n",
    "    inner_env = PendulumEnv(T = Float32, rng = rng)\n",
    "    A = action_space(inner_env)\n",
    "    low = A.left\n",
    "    high = A.right\n",
    "    ns = length(state(inner_env))\n",
    "\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 2048\n",
    "    env = MultiThreadEnv([\n",
    "        PendulumEnv(T = Float32, rng = StableRNG(hash(seed + i))) |>\n",
    "        env -> ActionTransformedEnv(env, action_mapping = x -> clamp(x * 2, low, high)) for i in 1:N_ENV\n",
    "    ])\n",
    "\n",
    "    init = glorot_uniform(rng)\n",
    "\n",
    "    agent = Agent(\n",
    "        policy = PPOPolicy(\n",
    "            approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                        Dense(ns, 64, relu; init = glorot_uniform(rng)),\n",
    "                        Dense(64, 64, relu; init = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(64, 1, tanh; init = glorot_uniform(rng)), vec),\n",
    "                    logσ = Chain(Dense(64, 1; init = glorot_uniform(rng)), vec),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 64, relu; init = glorot_uniform(rng)),\n",
    "                    Dense(64, 64, relu; init = glorot_uniform(rng)),\n",
    "                    Dense(64, 1; init = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(3e-4),\n",
    "            ) |> gpu,\n",
    "            γ = 0.99f0,\n",
    "            λ = 0.95f0,\n",
    "            clip_range = 0.2f0,\n",
    "            max_grad_norm = 0.5f0,\n",
    "            n_epochs = 10,\n",
    "            n_microbatches = 32,\n",
    "            actor_loss_weight = 1.0f0,\n",
    "            critic_loss_weight = 0.5f0,\n",
    "            entropy_loss_weight = 0.00f0,\n",
    "            dist = Normal,\n",
    "            rng = rng,\n",
    "            update_freq = UPDATE_FREQ,\n",
    "        ),\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float32} => (ns, N_ENV),\n",
    "            action = Vector{Float32} => (N_ENV,),\n",
    "            action_log_prob = Vector{Float32} => (N_ENV,),\n",
    "            reward = Vector{Float32} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    stop_condition = StopAfterStep(50_000, is_show_progress=!haskey(ENV, \"CI\"))\n",
    "    hook = TotalBatchRewardPerEpisode(N_ENV)\n",
    "    Experiment(agent, env, stop_condition, hook, \"# Play Pendulum with PPO\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a720cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux /home/richard/.julia/packages/Flux/7nTyc/src/functor.jl:187\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{Play Pendulum with PPO}\n"
      ],
      "text/markdown": [
       "# Play Pendulum with PPO\n"
      ],
      "text/plain": [
       "\u001b[1m  Play Pendulum with PPO\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m5:13\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mAvg total reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀ \n",
      "               \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "             \u001b[38;5;8m0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⢠\u001b[0m\u001b[38;5;1m⣾\u001b[0m\u001b[38;5;1m⣷\u001b[0m\u001b[38;5;1m⡿\u001b[0m\u001b[38;5;1m⣶\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣴\u001b[0m\u001b[38;5;1m⣷\u001b[0m\u001b[38;5;1m⠃\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⢠\u001b[0m\u001b[38;5;1m⣴\u001b[0m\u001b[38;5;1m⣸\u001b[0m\u001b[38;5;1m⠟\u001b[0m\u001b[38;5;3m⣯\u001b[0m\u001b[38;5;7m⣧\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;6m⣶\u001b[0m\u001b[38;5;7m⣾\u001b[0m\u001b[38;5;3m⣸\u001b[0m\u001b[38;5;2m⡆\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⣼\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;2m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣧\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⢻\u001b[0m\u001b[38;5;4m⡆\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;7m⣾\u001b[0m\u001b[38;5;6m⢫\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠻\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡟\u001b[0m\u001b[38;5;4m⢻\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⢸\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣾\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⡏\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀\u001b[38;5;4m⠸\u001b[0m\u001b[38;5;4m⡇\u001b[0m\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;1m⢀\u001b[0m⠀⠀⠀⠀\u001b[38;5;1m⢰\u001b[0m⠀\u001b[38;5;1m⣠\u001b[0m⠀\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⣧\u001b[0m\u001b[38;5;1m⣧\u001b[0m\u001b[38;5;1m⢸\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣧\u001b[0m\u001b[38;5;3m⣷\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⢸\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;1m⣄\u001b[0m\u001b[38;5;1m⣆\u001b[0m\u001b[38;5;1m⢠\u001b[0m\u001b[38;5;1m⣼\u001b[0m\u001b[38;5;1m⣦\u001b[0m\u001b[38;5;1m⢰\u001b[0m\u001b[38;5;1m⣴\u001b[0m\u001b[38;5;1m⣼\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣷\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⡷\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⡿\u001b[0m\u001b[38;5;3m⣝\u001b[0m\u001b[38;5;3m⢧\u001b[0m\u001b[38;5;3m⣾\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⡏\u001b[0m\u001b[38;5;6m⣯\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⡇\u001b[0m\u001b[38;5;4m⠏\u001b[0m\u001b[38;5;4m⠈\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣼\u001b[0m\u001b[38;5;3m⢚\u001b[0m\u001b[38;5;1m⠋\u001b[0m\u001b[38;5;1m⠿\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣇\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣶\u001b[0m\u001b[38;5;6m⡿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣟\u001b[0m\u001b[38;5;6m⢿\u001b[0m\u001b[38;5;6m⣯\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠛\u001b[0m\u001b[38;5;4m⢻\u001b[0m\u001b[38;5;4m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;1m⠏\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣾\u001b[0m\u001b[38;5;2m⣰\u001b[0m\u001b[38;5;2m⣦\u001b[0m\u001b[38;5;1m⠹\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⡿\u001b[0m\u001b[38;5;6m⡿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣷\u001b[0m\u001b[38;5;4m⠿\u001b[0m\u001b[38;5;4m⠟\u001b[0m\u001b[38;5;4m⠟\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⠛\u001b[0m\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡇\u001b[0m⠀\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⣾\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⢏\u001b[0m\u001b[38;5;6m⢏\u001b[0m\u001b[38;5;2m⢻\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣧\u001b[0m\u001b[38;5;4m⡇\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡏\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;6m⢁\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⢸\u001b[0m\u001b[38;5;4m⣾\u001b[0m\u001b[38;5;6m⡞\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠿\u001b[0m\u001b[38;5;4m⠁\u001b[0m\u001b[38;5;4m⣿\u001b[0m⠀⠀⠀⠀\u001b[38;5;4m⠈\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;4m⣾\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠙\u001b[0m\u001b[38;5;4m⡏\u001b[0m\u001b[38;5;4m⠇\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡿\u001b[0m\u001b[38;5;4m⠋\u001b[0m⠀⠀\u001b[38;5;4m⠟\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;4m⠻\u001b[0m⠀⠀⠀⠀\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-2000\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "               \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "               ⠀\u001b[38;5;8m0\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m300\u001b[0m⠀ \n",
      "               ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{Play Pendulum with PPO}\n"
      ],
      "text/markdown": [
       "# Play Pendulum with PPO\n"
      ],
      "text/plain": [
       "\u001b[1m  Play Pendulum with PPO\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "typename(Experiment)\n",
       "├─ policy => typename(Agent)\n",
       "│  ├─ policy => typename(PPOPolicy)\n",
       "│  │  ├─ approximator => typename(ActorCritic)\n",
       "│  │  │  ├─ actor => typename(GaussianNetwork)\n",
       "│  │  │  │  ├─ pre => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 64×3 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(relu))\n",
       "│  │  │  │  │     └─ 2\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 64×64 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(relu))\n",
       "│  │  │  │  ├─ μ => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 1×64 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(tanh))\n",
       "│  │  │  │  │     └─ 2\n",
       "│  │  │  │  │        └─ typename(typeof(vec))\n",
       "│  │  │  │  ├─ logσ => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 1×64 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  │     └─ 2\n",
       "│  │  │  │  │        └─ typename(typeof(vec))\n",
       "│  │  │  │  ├─ min_σ => 0.0\n",
       "│  │  │  │  ├─ max_σ => Inf\n",
       "│  │  │  │  └─ normalizer => typename(typeof(tanh))\n",
       "│  │  │  ├─ critic => typename(Chain)\n",
       "│  │  │  │  └─ layers\n",
       "│  │  │  │     ├─ 1\n",
       "│  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │     │     ├─ weight => 64×3 Matrix{Float32}\n",
       "│  │  │  │     │     ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │     │     └─ σ => typename(typeof(relu))\n",
       "│  │  │  │     ├─ 2\n",
       "│  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │     │     ├─ weight => 64×64 Matrix{Float32}\n",
       "│  │  │  │     │     ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │     │     └─ σ => typename(typeof(relu))\n",
       "│  │  │  │     └─ 3\n",
       "│  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │           ├─ weight => 1×64 Matrix{Float32}\n",
       "│  │  │  │           ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  └─ optimizer => typename(ADAM)\n",
       "│  │  │     ├─ eta => 0.0003\n",
       "│  │  │     ├─ beta\n",
       "│  │  │     │  ├─ 1\n",
       "│  │  │     │  │  └─ 0.9\n",
       "│  │  │     │  └─ 2\n",
       "│  │  │     │     └─ 0.999\n",
       "│  │  │     ├─ epsilon => 1.0e-8\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ γ => 0.99\n",
       "│  │  ├─ λ => 0.95\n",
       "│  │  ├─ clip_range => 0.2\n",
       "│  │  ├─ max_grad_norm => 0.5\n",
       "│  │  ├─ n_microbatches => 32\n",
       "│  │  ├─ n_epochs => 10\n",
       "│  │  ├─ actor_loss_weight => 1.0\n",
       "│  │  ├─ critic_loss_weight => 0.5\n",
       "│  │  ├─ entropy_loss_weight => 0.0\n",
       "│  │  ├─ rng => typename(StableRNGs.LehmerRNG)\n",
       "│  │  ├─ n_random_start => 0\n",
       "│  │  ├─ update_freq => 2048\n",
       "│  │  ├─ update_step => 50000\n",
       "│  │  ├─ norm => 32×10 Matrix{Float32}\n",
       "│  │  ├─ actor_loss => 32×10 Matrix{Float32}\n",
       "│  │  ├─ critic_loss => 32×10 Matrix{Float32}\n",
       "│  │  ├─ entropy_loss => 32×10 Matrix{Float32}\n",
       "│  │  └─ loss => 32×10 Matrix{Float32}\n",
       "│  └─ trajectory => typename(Trajectory)\n",
       "│     └─ traces => typename(NamedTuple)\n",
       "│        ├─ action_log_prob => 8×2049 CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}\n",
       "│        ├─ state => 3×8×2049 CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}\n",
       "│        ├─ action => 8×2049 CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}\n",
       "│        ├─ reward => 8×2048 CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}\n",
       "│        └─ terminal => 8×2048 CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}\n",
       "├─ env => typename(MultiThreadEnv)\n",
       "├─ stop_condition => typename(StopAfterStep)\n",
       "│  ├─ step => 50000\n",
       "│  ├─ cur => 50001\n",
       "│  └─ progress => typename(ProgressMeter.Progress)\n",
       "├─ hook => typename(TotalBatchRewardPerEpisode)\n",
       "│  ├─ rewards => 8-element Vector{Vector{Float64}}\n",
       "│  ├─ reward => 8-element Vector{Float64}\n",
       "│  └─ is_display_on_exit => true\n",
       "└─ description => \"# Play Pendulum with PPO\"\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pkg.add(\"Plots\")\n",
    "using Plots\n",
    "using Statistics\n",
    "ex = E`JuliaRL_PPO_Pendulum`\n",
    "run(ex)\n",
    "# n = minimum(map(length, ex.hook.rewards))\n",
    "# m = mean([@view(x[1:n]) for x in ex.hook.rewards])\n",
    "# s = std([@view(x[1:n]) for x in ex.hook.rewards])\n",
    "# plot(m,ribbon=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d2563",
   "metadata": {},
   "source": [
    "## 3. Break down the experiment running implementation\n",
    "\n",
    "[reference: JuliaRinforcementLearning Blog](https://juliareinforcementlearning.org/blog/an_introduction_to_reinforcement_learning_jl_design_implementations_thoughts/#ol_start2_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82dcb36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# PendulumEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                  Value |\n",
       "|:----------------- | ----------------------:|\n",
       "| NumAgentStyle     |          SingleAgent() |\n",
       "| DynamicStyle      |           Sequential() |\n",
       "| InformationStyle  | ImperfectInformation() |\n",
       "| ChanceStyle       |           Stochastic() |\n",
       "| RewardStyle       |           StepReward() |\n",
       "| UtilityStyle      |           GeneralSum() |\n",
       "| ActionStyle       |     MinimalActionSet() |\n",
       "| StateStyle        |     Observation{Any}() |\n",
       "| DefaultStateStyle |     Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{IntervalSets.ClosedInterval{Float32}}}(IntervalSets.ClosedInterval{Float32}[-1.0..1.0, -1.0..1.0, -8.0..8.0])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`-2.0..2.0`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "Float32[0.85257685, -0.52260184, -0.876019]\n",
       "```\n"
      ],
      "text/plain": [
       "# PendulumEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                  Value |\n",
       "|:----------------- | ----------------------:|\n",
       "| NumAgentStyle     |          SingleAgent() |\n",
       "| DynamicStyle      |           Sequential() |\n",
       "| InformationStyle  | ImperfectInformation() |\n",
       "| ChanceStyle       |           Stochastic() |\n",
       "| RewardStyle       |           StepReward() |\n",
       "| UtilityStyle      |           GeneralSum() |\n",
       "| ActionStyle       |     MinimalActionSet() |\n",
       "| StateStyle        |     Observation{Any}() |\n",
       "| DefaultStateStyle |     Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Space{Vector{IntervalSets.ClosedInterval{Float32}}}(IntervalSets.ClosedInterval{Float32}[-1.0..1.0, -1.0..1.0, -8.0..8.0])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`-2.0..2.0`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "Float32[0.85257685, -0.52260184, -0.876019]\n",
       "```\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123;\n",
    "rng = StableRNG(seed);\n",
    "env = PendulumEnv(T = Float32, rng = rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8bed7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_run (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "function custom_run(policy, env, stop_criterion)\n",
    "    while true\n",
    "        reset!(env)\n",
    "        policy(PRE_EPISODE_STAGE)\n",
    "        while !is_terminated(env)\n",
    "            #env |> policy |> env\n",
    "            action = policy(env)\n",
    "            policy(PRE_ACT_STAGE, env, action)\n",
    "            env(action)\n",
    "            policy(POST_ACT_STAGE, env)\n",
    "            stop_condition(policy, env) && return\n",
    "        end\n",
    "        policy(POST_EPISODE_STAGE)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4861f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb78fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f486a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950d59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7fe6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1b0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433827cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c1783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76367d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
