{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe242f8",
   "metadata": {},
   "source": [
    "## 1. A gentle example of using ReinforcementLearning.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec02870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg;\n",
    "# uncomment the following if you have not installed them\n",
    "# Pkg.add(\"ReinforcementLearning\");\n",
    "# Pkg.add(\"Flux\");\n",
    "# Pkg.add(\"StableRNGs\");\n",
    "# Pkg.add(\"Distributions\");\n",
    "using Flux: InvDecay;\n",
    "using ReinforcementLearning;\n",
    "using StableRNGs;\n",
    "using Flux;\n",
    "using Flux.Losses;\n",
    "using Distributions;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb0dd9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# RandomWalk1D\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                Value |\n",
       "|:----------------- | --------------------:|\n",
       "| NumAgentStyle     |        SingleAgent() |\n",
       "| DynamicStyle      |         Sequential() |\n",
       "| InformationStyle  | PerfectInformation() |\n",
       "| ChanceStyle       |      Deterministic() |\n",
       "| RewardStyle       |     TerminalReward() |\n",
       "| UtilityStyle      |         GeneralSum() |\n",
       "| ActionStyle       |   MinimalActionSet() |\n",
       "| StateStyle        | Observation{Int64}() |\n",
       "| DefaultStateStyle | Observation{Int64}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Base.OneTo(7)`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(2)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "4\n",
       "```\n"
      ],
      "text/plain": [
       "# RandomWalk1D\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                Value |\n",
       "|:----------------- | --------------------:|\n",
       "| NumAgentStyle     |        SingleAgent() |\n",
       "| DynamicStyle      |         Sequential() |\n",
       "| InformationStyle  | PerfectInformation() |\n",
       "| ChanceStyle       |      Deterministic() |\n",
       "| RewardStyle       |     TerminalReward() |\n",
       "| UtilityStyle      |         GeneralSum() |\n",
       "| ActionStyle       |   MinimalActionSet() |\n",
       "| StateStyle        | Observation{Int64}() |\n",
       "| DefaultStateStyle | Observation{Int64}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`Base.OneTo(7)`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`Base.OneTo(2)`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "4\n",
       "```\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = RandomWalk1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f8f2a",
   "metadata": {},
   "source": [
    "### random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87c63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = action_space(env)\n",
    "while true\n",
    "    env(rand(A))\n",
    "    is_terminated(env) && break\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61151f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "            \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "          \u001b[38;5;8m1\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⣷\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⣇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⣸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⢻\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢰\u001b[0m\u001b[38;5;2m⢹\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡏\u001b[0m\u001b[38;5;2m⡆\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⡆\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢰\u001b[0m\u001b[38;5;2m⠁\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⡎\u001b[0m⠀\u001b[38;5;2m⢇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀\u001b[38;5;2m⠸\u001b[0m\u001b[38;5;2m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀\u001b[38;5;2m⠈\u001b[0m\u001b[38;5;2m⡆\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀\u001b[38;5;2m⠸\u001b[0m\u001b[38;5;2m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;2m⡸\u001b[0m⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⡎\u001b[0m⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀\u001b[38;5;2m⢱\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score   \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠤⠤\u001b[38;5;2m⡧\u001b[0m⠤⠤⠤\u001b[38;5;2m⢼\u001b[0m⠤⠤⠤⠤\u001b[38;5;2m⡧\u001b[0m⠤⠤⠤\u001b[38;5;2m⢧\u001b[0m⠤⠤⠤⠤⠤⠤⠤⠤\u001b[38;5;2m⡼\u001b[0m⠤⠤⠤\u001b[38;5;2m⢼\u001b[0m⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀\u001b[38;5;2m⠸\u001b[0m\u001b[38;5;2m⡀\u001b[0m⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀\u001b[38;5;2m⡸\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢣\u001b[0m⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡸\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀\u001b[38;5;2m⠘\u001b[0m\u001b[38;5;2m⡄\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⠘\u001b[0m\u001b[38;5;2m⡄\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⡜\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢇\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-1\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⢱\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⡎\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;2m⠸\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;2m⣀\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "            ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([-1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0], 0.0, true)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\n",
    "    RandomPolicy(),\n",
    "    RandomWalk1D(),\n",
    "    StopAfterEpisode(10),\n",
    "    TotalRewardPerEpisode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f083a2",
   "metadata": {},
   "source": [
    "### tabular policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92206641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tabular policy\n",
    "S = state_space(env);\n",
    "A = action_space(env);\n",
    "NS, NA = length(S),A;\n",
    "tabular_policy = TabularPolicy(;table=Dict(zip(1:NS, fill(2,NS))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e83dfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "           \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "         \u001b[38;5;8m2\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score  \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "          \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "           ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "           ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.0, true)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\n",
    "   tabular_policy,\n",
    "   RandomWalk1D(),\n",
    "   StopAfterEpisode(10),\n",
    "   TotalRewardPerEpisode()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b22067",
   "metadata": {},
   "source": [
    "### `QBasedPolicy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23addc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(QBasedPolicy)\n",
       "├─ learner => typename(MonteCarloLearner)\n",
       "│  ├─ approximator => typename(TabularApproximator)\n",
       "│  │  ├─ table => 2×7 Matrix{Float64}\n",
       "│  │  └─ optimizer => typename(InvDecay)\n",
       "│  │     ├─ gamma => 1.0\n",
       "│  │     └─ state => typename(IdDict)\n",
       "│  ├─ γ => 1.0\n",
       "│  ├─ kind => typename(ReinforcementLearningZoo.FirstVisit)\n",
       "│  └─ sampling => typename(ReinforcementLearningZoo.NoSampling)\n",
       "└─ explorer => typename(EpsilonGreedyExplorer)\n",
       "   ├─ ϵ_stable => 0.1\n",
       "   ├─ ϵ_init => 1.0\n",
       "   ├─ warmup_steps => 0\n",
       "   ├─ decay_steps => 0\n",
       "   ├─ step => 1\n",
       "   ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "   └─ is_training => true\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `MonteCarloLearner + EpsilonGreedyExplorer`\n",
    "policy = QBasedPolicy(\n",
    "   learner = MonteCarloLearner(;\n",
    "           approximator=TabularQApproximator(\n",
    "               ;n_state = NS,\n",
    "               n_action = NA,\n",
    "               opt = InvDecay(1.0)\n",
    "           )\n",
    "       ),\n",
    "   explorer = EpsilonGreedyExplorer(0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03daa1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "            \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "          \u001b[38;5;8m0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score   \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;2m⠤\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-2\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "            ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], 0.0, true)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\n",
    "   policy,\n",
    "   RandomWalk1D(),\n",
    "   StopAfterEpisode(10),\n",
    "   TotalRewardPerEpisode()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de87e2",
   "metadata": {},
   "source": [
    "### wrap the policy + trajectory into the 'agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940bd60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typename(Agent)\n",
       "├─ policy => typename(QBasedPolicy)\n",
       "│  ├─ learner => typename(MonteCarloLearner)\n",
       "│  │  ├─ approximator => typename(TabularApproximator)\n",
       "│  │  │  ├─ table => 2×7 Matrix{Float64}\n",
       "│  │  │  └─ optimizer => typename(InvDecay)\n",
       "│  │  │     ├─ gamma => 1.0\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ γ => 1.0\n",
       "│  │  ├─ kind => typename(ReinforcementLearningZoo.FirstVisit)\n",
       "│  │  └─ sampling => typename(ReinforcementLearningZoo.NoSampling)\n",
       "│  └─ explorer => typename(EpsilonGreedyExplorer)\n",
       "│     ├─ ϵ_stable => 0.1\n",
       "│     ├─ ϵ_init => 1.0\n",
       "│     ├─ warmup_steps => 0\n",
       "│     ├─ decay_steps => 0\n",
       "│     ├─ step => 31\n",
       "│     ├─ rng => typename(Random._GLOBAL_RNG)\n",
       "│     └─ is_training => true\n",
       "└─ trajectory => typename(Trajectory)\n",
       "   └─ traces => typename(NamedTuple)\n",
       "      ├─ state => 0-element Vector{Int64}\n",
       "      ├─ action => 0-element Vector{Int64}\n",
       "      ├─ reward => 0-element Vector{Float32}\n",
       "      └─ terminal => 0-element Vector{Bool}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Agent(policy=policy, trajectory=VectorSARTTrajectory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cddd4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mTotal reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n",
      "            \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "          \u001b[38;5;8m1\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀\u001b[38;5;2m⡏\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;2m⠉\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⡎\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;2m⡸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score   \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠤⠤\u001b[38;5;2m⡧\u001b[0m⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⢠\u001b[0m\u001b[38;5;2m⠃\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⢀\u001b[0m\u001b[38;5;2m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⢸\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "           \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⡜\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-1\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "            \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "            ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m10\u001b[0m⠀ \n",
      "            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TotalRewardPerEpisode([-1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 0.0, true)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(agent, env, StopAfterEpisode(10), TotalRewardPerEpisode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53760509",
   "metadata": {},
   "source": [
    "## 2. PPO algorithm for pendulum problem (built-in experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c66a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "function RL.Experiment(\n",
    "    ::Val{:JuliaRL},\n",
    "    ::Val{:PPO},\n",
    "    ::Val{:Pendulum},\n",
    "    ::Nothing;\n",
    "    save_dir = nothing,\n",
    "    seed = 123,\n",
    ")\n",
    "    rng = StableRNG(seed)\n",
    "    inner_env = PendulumEnv(T = Float32, rng = rng)\n",
    "    A = action_space(inner_env)\n",
    "    low = A.left\n",
    "    high = A.right\n",
    "    ns = length(state(inner_env))\n",
    "\n",
    "    N_ENV = 8\n",
    "    UPDATE_FREQ = 2048\n",
    "    env = MultiThreadEnv([\n",
    "        PendulumEnv(T = Float32, rng = StableRNG(hash(seed + i))) |>\n",
    "        env -> ActionTransformedEnv(env, action_mapping = x -> clamp(x * 2, low, high)) for i in 1:N_ENV\n",
    "    ])\n",
    "\n",
    "    init = glorot_uniform(rng)\n",
    "\n",
    "    agent = Agent(\n",
    "        policy = PPOPolicy(\n",
    "            approximator = ActorCritic(\n",
    "                actor = GaussianNetwork(\n",
    "                    pre = Chain(\n",
    "                        Dense(ns, 64, relu; init = glorot_uniform(rng)),\n",
    "                        Dense(64, 64, relu; init = glorot_uniform(rng)),\n",
    "                    ),\n",
    "                    μ = Chain(Dense(64, 1, tanh; init = glorot_uniform(rng)), vec),\n",
    "                    logσ = Chain(Dense(64, 1; init = glorot_uniform(rng)), vec),\n",
    "                ),\n",
    "                critic = Chain(\n",
    "                    Dense(ns, 64, relu; init = glorot_uniform(rng)),\n",
    "                    Dense(64, 64, relu; init = glorot_uniform(rng)),\n",
    "                    Dense(64, 1; init = glorot_uniform(rng)),\n",
    "                ),\n",
    "                optimizer = ADAM(3e-4),\n",
    "            ) |> gpu,\n",
    "            γ = 0.99f0,\n",
    "            λ = 0.95f0,\n",
    "            clip_range = 0.2f0,\n",
    "            max_grad_norm = 0.5f0,\n",
    "            n_epochs = 10,\n",
    "            n_microbatches = 32,\n",
    "            actor_loss_weight = 1.0f0,\n",
    "            critic_loss_weight = 0.5f0,\n",
    "            entropy_loss_weight = 0.00f0,\n",
    "            dist = Normal,\n",
    "            rng = rng,\n",
    "            update_freq = UPDATE_FREQ,\n",
    "        ),\n",
    "        trajectory = PPOTrajectory(;\n",
    "            capacity = UPDATE_FREQ,\n",
    "            state = Matrix{Float32} => (ns, N_ENV),\n",
    "            action = Vector{Float32} => (N_ENV,),\n",
    "            action_log_prob = Vector{Float32} => (N_ENV,),\n",
    "            reward = Vector{Float32} => (N_ENV,),\n",
    "            terminal = Vector{Bool} => (N_ENV,),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    stop_condition = StopAfterStep(50_000, is_show_progress=!haskey(ENV, \"CI\"))\n",
    "    hook = TotalBatchRewardPerEpisode(N_ENV)\n",
    "    Experiment(agent, env, stop_condition, hook, \"# Play Pendulum with PPO\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4b9978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "┌ Info: The GPU function is being called but the GPU is not accessible. \n",
      "│ Defaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "└ @ Flux /home/richard/.julia/packages/Flux/7nTyc/src/functor.jl:187\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{Play Pendulum with PPO}\n"
      ],
      "text/markdown": [
       "# Play Pendulum with PPO\n"
      ],
      "text/plain": [
       "\u001b[1m  Play Pendulum with PPO\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m9:52\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ⠀⠀⠀⠀⠀⠀⠀\u001b[97;1mAvg total reward per episode\u001b[0m⠀⠀⠀⠀⠀⠀⠀ \n",
      "               \u001b[38;5;8m┌────────────────────────────────────────┐\u001b[0m \n",
      "             \u001b[38;5;8m0\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⢠\u001b[0m\u001b[38;5;1m⣾\u001b[0m\u001b[38;5;1m⣷\u001b[0m\u001b[38;5;1m⡿\u001b[0m\u001b[38;5;1m⣶\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣴\u001b[0m\u001b[38;5;1m⣷\u001b[0m\u001b[38;5;1m⠃\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⢠\u001b[0m\u001b[38;5;1m⣴\u001b[0m\u001b[38;5;1m⣸\u001b[0m\u001b[38;5;1m⠟\u001b[0m\u001b[38;5;3m⣯\u001b[0m\u001b[38;5;7m⣧\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;6m⣶\u001b[0m\u001b[38;5;7m⣾\u001b[0m\u001b[38;5;3m⣸\u001b[0m\u001b[38;5;2m⡆\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⣼\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;2m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣧\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⢻\u001b[0m\u001b[38;5;4m⡆\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;7m⣾\u001b[0m\u001b[38;5;6m⢫\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠻\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡟\u001b[0m\u001b[38;5;4m⢻\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠇\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⢀\u001b[0m\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⢸\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣾\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⡏\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀\u001b[38;5;4m⠸\u001b[0m\u001b[38;5;4m⡇\u001b[0m\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀\u001b[38;5;1m⢀\u001b[0m⠀⠀⠀⠀\u001b[38;5;1m⢰\u001b[0m⠀\u001b[38;5;1m⣠\u001b[0m⠀\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⡀\u001b[0m\u001b[38;5;1m⣧\u001b[0m\u001b[38;5;1m⣧\u001b[0m\u001b[38;5;1m⢸\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣧\u001b[0m\u001b[38;5;3m⣷\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⢸\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;1m⣄\u001b[0m\u001b[38;5;1m⣆\u001b[0m\u001b[38;5;1m⢠\u001b[0m\u001b[38;5;1m⣼\u001b[0m\u001b[38;5;1m⣦\u001b[0m\u001b[38;5;1m⢰\u001b[0m\u001b[38;5;1m⣴\u001b[0m\u001b[38;5;1m⣼\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⣷\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;1m⡷\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⡿\u001b[0m\u001b[38;5;3m⣝\u001b[0m\u001b[38;5;3m⢧\u001b[0m\u001b[38;5;3m⣾\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⡏\u001b[0m\u001b[38;5;6m⣯\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⡇\u001b[0m\u001b[38;5;4m⠏\u001b[0m\u001b[38;5;4m⠈\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "   Score      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣼\u001b[0m\u001b[38;5;3m⢚\u001b[0m\u001b[38;5;1m⠋\u001b[0m\u001b[38;5;1m⠿\u001b[0m\u001b[38;5;1m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;3m⣇\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣶\u001b[0m\u001b[38;5;6m⡿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣟\u001b[0m\u001b[38;5;6m⢿\u001b[0m\u001b[38;5;6m⣯\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠛\u001b[0m\u001b[38;5;4m⢻\u001b[0m\u001b[38;5;4m⡇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;1m⠏\u001b[0m\u001b[38;5;7m⣿\u001b[0m\u001b[38;5;6m⣾\u001b[0m\u001b[38;5;2m⣰\u001b[0m\u001b[38;5;2m⣦\u001b[0m\u001b[38;5;1m⠹\u001b[0m\u001b[38;5;3m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⡿\u001b[0m\u001b[38;5;6m⡿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣷\u001b[0m\u001b[38;5;4m⠿\u001b[0m\u001b[38;5;4m⠟\u001b[0m\u001b[38;5;4m⠟\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⠛\u001b[0m\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡇\u001b[0m⠀\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;2m⣾\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⢏\u001b[0m\u001b[38;5;6m⢏\u001b[0m\u001b[38;5;2m⢻\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣧\u001b[0m\u001b[38;5;4m⡇\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡏\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;6m⢁\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⢸\u001b[0m\u001b[38;5;4m⣾\u001b[0m\u001b[38;5;6m⡞\u001b[0m\u001b[38;5;6m⣿\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠿\u001b[0m\u001b[38;5;4m⠁\u001b[0m\u001b[38;5;4m⣿\u001b[0m⠀⠀⠀⠀\u001b[38;5;4m⠈\u001b[0m\u001b[38;5;4m⠁\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;4m⣾\u001b[0m\u001b[38;5;4m⣿\u001b[0m\u001b[38;5;4m⠙\u001b[0m\u001b[38;5;4m⡏\u001b[0m\u001b[38;5;4m⠇\u001b[0m\u001b[38;5;4m⢿\u001b[0m\u001b[38;5;4m⡿\u001b[0m\u001b[38;5;4m⠋\u001b[0m⠀⠀\u001b[38;5;4m⠟\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;4m⠻\u001b[0m⠀⠀⠀⠀\u001b[38;5;4m⠘\u001b[0m\u001b[38;5;4m⠇\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "              \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "         \u001b[38;5;8m-2000\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m\n",
      "               \u001b[38;5;8m└────────────────────────────────────────┘\u001b[0m \n",
      "               ⠀\u001b[38;5;8m0\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m300\u001b[0m⠀ \n",
      "               ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀Episode⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀ \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{Play Pendulum with PPO}\n"
      ],
      "text/markdown": [
       "# Play Pendulum with PPO\n"
      ],
      "text/plain": [
       "\u001b[1m  Play Pendulum with PPO\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "typename(Experiment)\n",
       "├─ policy => typename(Agent)\n",
       "│  ├─ policy => typename(PPOPolicy)\n",
       "│  │  ├─ approximator => typename(ActorCritic)\n",
       "│  │  │  ├─ actor => typename(GaussianNetwork)\n",
       "│  │  │  │  ├─ pre => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 64×3 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(relu))\n",
       "│  │  │  │  │     └─ 2\n",
       "│  │  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │  │           ├─ weight => 64×64 Matrix{Float32}\n",
       "│  │  │  │  │           ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │  │           └─ σ => typename(typeof(relu))\n",
       "│  │  │  │  ├─ μ => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 1×64 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(tanh))\n",
       "│  │  │  │  │     └─ 2\n",
       "│  │  │  │  │        └─ typename(typeof(vec))\n",
       "│  │  │  │  ├─ logσ => typename(Chain)\n",
       "│  │  │  │  │  └─ layers\n",
       "│  │  │  │  │     ├─ 1\n",
       "│  │  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │  │     │     ├─ weight => 1×64 Matrix{Float32}\n",
       "│  │  │  │  │     │     ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │  │     │     └─ σ => typename(typeof(identity))\n",
       "│  │  │  │  │     └─ 2\n",
       "│  │  │  │  │        └─ typename(typeof(vec))\n",
       "│  │  │  │  ├─ min_σ => 0.0\n",
       "│  │  │  │  ├─ max_σ => Inf\n",
       "│  │  │  │  └─ normalizer => typename(typeof(tanh))\n",
       "│  │  │  ├─ critic => typename(Chain)\n",
       "│  │  │  │  └─ layers\n",
       "│  │  │  │     ├─ 1\n",
       "│  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │     │     ├─ weight => 64×3 Matrix{Float32}\n",
       "│  │  │  │     │     ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │     │     └─ σ => typename(typeof(relu))\n",
       "│  │  │  │     ├─ 2\n",
       "│  │  │  │     │  └─ typename(Dense)\n",
       "│  │  │  │     │     ├─ weight => 64×64 Matrix{Float32}\n",
       "│  │  │  │     │     ├─ bias => 64-element Vector{Float32}\n",
       "│  │  │  │     │     └─ σ => typename(typeof(relu))\n",
       "│  │  │  │     └─ 3\n",
       "│  │  │  │        └─ typename(Dense)\n",
       "│  │  │  │           ├─ weight => 1×64 Matrix{Float32}\n",
       "│  │  │  │           ├─ bias => 1-element Vector{Float32}\n",
       "│  │  │  │           └─ σ => typename(typeof(identity))\n",
       "│  │  │  └─ optimizer => typename(ADAM)\n",
       "│  │  │     ├─ eta => 0.0003\n",
       "│  │  │     ├─ beta\n",
       "│  │  │     │  ├─ 1\n",
       "│  │  │     │  │  └─ 0.9\n",
       "│  │  │     │  └─ 2\n",
       "│  │  │     │     └─ 0.999\n",
       "│  │  │     ├─ epsilon => 1.0e-8\n",
       "│  │  │     └─ state => typename(IdDict)\n",
       "│  │  ├─ γ => 0.99\n",
       "│  │  ├─ λ => 0.95\n",
       "│  │  ├─ clip_range => 0.2\n",
       "│  │  ├─ max_grad_norm => 0.5\n",
       "│  │  ├─ n_microbatches => 32\n",
       "│  │  ├─ n_epochs => 10\n",
       "│  │  ├─ actor_loss_weight => 1.0\n",
       "│  │  ├─ critic_loss_weight => 0.5\n",
       "│  │  ├─ entropy_loss_weight => 0.0\n",
       "│  │  ├─ rng => typename(StableRNGs.LehmerRNG)\n",
       "│  │  ├─ n_random_start => 0\n",
       "│  │  ├─ update_freq => 2048\n",
       "│  │  ├─ update_step => 50000\n",
       "│  │  ├─ norm => 32×10 Matrix{Float32}\n",
       "│  │  ├─ actor_loss => 32×10 Matrix{Float32}\n",
       "│  │  ├─ critic_loss => 32×10 Matrix{Float32}\n",
       "│  │  ├─ entropy_loss => 32×10 Matrix{Float32}\n",
       "│  │  └─ loss => 32×10 Matrix{Float32}\n",
       "│  └─ trajectory => typename(Trajectory)\n",
       "│     └─ traces => typename(NamedTuple)\n",
       "│        ├─ action_log_prob => 8×2049 CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}\n",
       "│        ├─ state => 3×8×2049 CircularArrayBuffers.CircularArrayBuffer{Float32, 3, Array{Float32, 3}}\n",
       "│        ├─ action => 8×2049 CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}\n",
       "│        ├─ reward => 8×2048 CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}\n",
       "│        └─ terminal => 8×2048 CircularArrayBuffers.CircularArrayBuffer{Bool, 2, Matrix{Bool}}\n",
       "├─ env => typename(MultiThreadEnv)\n",
       "├─ stop_condition => typename(StopAfterStep)\n",
       "│  ├─ step => 50000\n",
       "│  ├─ cur => 50001\n",
       "│  └─ progress => typename(ProgressMeter.Progress)\n",
       "├─ hook => typename(TotalBatchRewardPerEpisode)\n",
       "│  ├─ rewards => 8-element Vector{Vector{Float64}}\n",
       "│  ├─ reward => 8-element Vector{Float64}\n",
       "│  └─ is_display_on_exit => true\n",
       "└─ description => \"# Play Pendulum with PPO\"\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    end\n",
    "    update!(opt, params(m), gs)\n",
    "  end\n",
    "  @show accuracy(valX, valY)\n",
    "endPkg.add(\"Plots\")\n",
    "using Plots\n",
    "using Statistics\n",
    "ex = E`JuliaRL_PPO_Pendulum`\n",
    "run(ex)\n",
    "# n = minimum(map(length, ex.hook.rewards))\n",
    "# m = mean([@view(x[1:n]) for x in ex.hook.rewards])\n",
    "# s = std([@view(x[1:n]) for x in ex.hook.rewards])\n",
    "# plot(m,ribbon=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8b1a4",
   "metadata": {},
   "source": [
    "## 3. Break down the experiment running implementation\n",
    "\n",
    "[reference: JuliaRinforcementLearning Blog](https://juliareinforcementlearning.org/blog/an_introduction_to_reinforcement_learning_jl_design_implementations_thoughts/#ol_start2_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71753530",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123;\n",
    "rng = StableRNG(seed);\n",
    "env = CartPoleEnv(; T = Float32);\n",
    "ns, na = length(state_space(env)), length(action_space(env));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f143670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_run (generic function with 3 methods)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function custom_run(\n",
    "        policy, \n",
    "        env, \n",
    "        stop_criterion = StopAfterEpisode(5),\n",
    "        hook = EmptyHook(),\n",
    "    )\n",
    "    step_counter = 0\n",
    "    while true\n",
    "        reset!(env)\n",
    "        #policy(PRE_EPISODE_STAGE)\n",
    "        \n",
    "        while !is_terminated(env)\n",
    "            #env |> policy |> env\n",
    "            action = policy(env)\n",
    "            step_counter = step_counter +1\n",
    "            \n",
    "            #policy(PRE_ACT_STAGE, env, action)\n",
    "            env(action)\n",
    "            \n",
    "            println(step_counter, reward(env))\n",
    "            \n",
    "            #policy(POST_ACT_STAGE, env)\n",
    "            stop_criterion(policy, env) && return\n",
    "        end\n",
    "        #policy(POST_EPISODE_STAGE)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd79a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dumm_policy (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dumm_policy(env)\n",
    "    return 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c75830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n",
      "21.0\n",
      "31.0\n",
      "41.0\n",
      "51.0\n",
      "61.0\n",
      "71.0\n",
      "80.0\n",
      "91.0\n",
      "101.0\n",
      "111.0\n",
      "121.0\n",
      "131.0\n",
      "141.0\n",
      "151.0\n",
      "161.0\n",
      "170.0\n",
      "181.0\n",
      "191.0\n",
      "201.0\n",
      "211.0\n",
      "221.0\n",
      "231.0\n",
      "241.0\n",
      "251.0\n",
      "261.0\n",
      "270.0\n",
      "281.0\n",
      "291.0\n",
      "301.0\n",
      "311.0\n",
      "321.0\n",
      "331.0\n",
      "341.0\n",
      "351.0\n",
      "361.0\n",
      "370.0\n",
      "381.0\n",
      "391.0\n",
      "401.0\n",
      "411.0\n",
      "421.0\n",
      "431.0\n",
      "441.0\n",
      "450.0\n",
      "461.0\n",
      "471.0\n",
      "481.0\n",
      "491.0\n",
      "501.0\n",
      "511.0\n",
      "521.0\n",
      "531.0\n",
      "541.0\n",
      "550.0\n",
      "561.0\n",
      "571.0\n",
      "581.0\n",
      "591.0\n",
      "601.0\n",
      "611.0\n",
      "621.0\n",
      "630.0\n",
      "641.0\n",
      "651.0\n",
      "661.0\n",
      "671.0\n",
      "681.0\n",
      "691.0\n",
      "701.0\n",
      "711.0\n",
      "721.0\n",
      "730.0\n",
      "741.0\n",
      "751.0\n",
      "761.0\n",
      "771.0\n",
      "781.0\n",
      "791.0\n",
      "801.0\n",
      "811.0\n",
      "820.0\n",
      "831.0\n",
      "841.0\n",
      "851.0\n",
      "861.0\n",
      "871.0\n",
      "881.0\n",
      "891.0\n",
      "901.0\n",
      "911.0\n",
      "920.0\n",
      "931.0\n",
      "941.0\n",
      "951.0\n",
      "961.0\n",
      "971.0\n",
      "981.0\n",
      "991.0\n",
      "1001.0\n",
      "1011.0\n",
      "1020.0\n",
      "1031.0\n",
      "1041.0\n",
      "1051.0\n",
      "1061.0\n",
      "1071.0\n",
      "1081.0\n",
      "1091.0\n",
      "1101.0\n",
      "1111.0\n",
      "1120.0\n",
      "1131.0\n",
      "1141.0\n",
      "1151.0\n",
      "1161.0\n",
      "1171.0\n",
      "1181.0\n",
      "1191.0\n",
      "1201.0\n",
      "1211.0\n",
      "1220.0\n",
      "1231.0\n",
      "1241.0\n",
      "1251.0\n",
      "1261.0\n",
      "1271.0\n",
      "1281.0\n",
      "1291.0\n",
      "1301.0\n",
      "1310.0\n",
      "1321.0\n",
      "1331.0\n",
      "1341.0\n",
      "1351.0\n",
      "1361.0\n",
      "1371.0\n",
      "1381.0\n",
      "1391.0\n",
      "1401.0\n",
      "1410.0\n"
     ]
    }
   ],
   "source": [
    "custom_run(dumm_policy, env, StopAfterEpisode(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08604c70",
   "metadata": {},
   "source": [
    "### 4. A Q-learning Agent\n",
    "\n",
    "For simplicity, we omit the explorer here for env with small state and action spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d51e260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "WARNING: both Distributions and Flux export \"params\"; uses of it in module Main must be qualified\n"
     ]
    }
   ],
   "source": [
    "export QBasedPolicy, TabularRandomPolicy\n",
    "\n",
    "Pkg.add(\"MacroTools\")\n",
    "Pkg.add(\"Setfield\")\n",
    "using MacroTools: @forward\n",
    "using Setfield: @set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a27cae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Dense(ns, 128, relu; init = glorot_uniform(rng)),\n",
    "    Dense(128, 128, relu; init = glorot_uniform(rng)),\n",
    "    Dense(128, na; init = glorot_uniform(rng)),\n",
    ") |> gpu;\n",
    "optimizer = ADAM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c8b014d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial output: Float32[-0.0019286007, -0.0044424515]\n",
      "updated output: Float32[-0.0019286007, -0.0044424515]\n"
     ]
    }
   ],
   "source": [
    "using Flux.Losses: mse\n",
    "println(\"initial output: \", model(state(env)))\n",
    "\n",
    "# a template update step\n",
    "function loss(states, action_label)\n",
    "    #action = argmax([model(states), model(states)], dims=2);\n",
    "    action = \n",
    "    return sum(mse(action, action_label))\n",
    "end\n",
    "\n",
    "y = [100, 100];\n",
    "states = state(env)\n",
    "\n",
    "g = Flux.gradient(()->loss(states, y), Flux.params(model))\n",
    "\n",
    "Flux.train!(loss, Flux.params(model), [(states, y)], optimizer)\n",
    "\n",
    "# for i = 1:5\n",
    "#     Flux.update!(optimizer, Flux.params(model), g)\n",
    "# end\n",
    "\n",
    "println(\"updated output: \", model(state(env)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cb71b4f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Only reference types can be differentiated with `Params`.",
     "output_type": "error",
     "traceback": [
      "Only reference types can be differentiated with `Params`.",
      "",
      "Stacktrace:",
      " [1] error(s::String)",
      "   @ Base ./error.jl:33",
      " [2] getindex(gs::Zygote.Grads, x::Int64)",
      "   @ Zygote ~/.julia/packages/Zygote/ytjqm/src/compiler/interface.jl:274",
      " [3] top-level scope",
      "   @ In[176]:1",
      " [4] eval",
      "   @ ./boot.jl:373 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "g[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0854a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b44df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d248d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23aae3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
